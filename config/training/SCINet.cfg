[base]
batch_size=16
epoch_num=100
gpu=0
visdom_ip=127.0.0.1
early_stop_patience=15

[obj]
training_loss=torch.nn.L1Loss()
mask=False
eval_metric=masked_mae,masked_rmse,masked_mape


[optim]
func=torch.optim.Adam
lr=1e-2
;weight_decay=1e-5


[scheduler]
func=torch.optim.lr_scheduler.MultiStepLR
gamma=0.5
milestones=[50]

[other]
save_model=False

